{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55760, 21)\n",
      "(13940, 20)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', parse_dates=['03', '04'])\n",
    "df_test = pd.read_csv('test.csv', parse_dates=['03', '04'])\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading the dataset, map the column names into a human understandable format\n",
    "column_mapping = {\n",
    "    'id': 'customer_id',\n",
    "    '02': 'gender', \n",
    "    '03': 'dob', \n",
    "    '04': 'lead_creation_date', \n",
    "    '05': 'city_code', \n",
    "    '06': 'area_code', \n",
    "    '07': 'employer_code', \n",
    "    '08': 'employer_category1', \n",
    "    '09': 'employer_category2', \n",
    "    '10': 'monthly_income', \n",
    "    '11': 'bank_code', \n",
    "    '12': 'bank_acc_type',\n",
    "    '13': 'marketing_source', \n",
    "    '14': 'marketing_category1', \n",
    "    '15': 'marketing_category2', \n",
    "    '16': 'current_loan_installment', \n",
    "    '17': 'requested_loan_amount', \n",
    "    '18': 'loan_repayment', \n",
    "    '19': 'interest_rate', \n",
    "    '20': 'requested_loan_installment', \n",
    "    'class': 'loan_approval_status'\n",
    "}\n",
    "\n",
    "df_train = df_train.rename(columns=column_mapping)\n",
    "df_test = df_test.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'requested_loan_installment' column in both train and test datasets\n",
    "# because this column is redundant with 'current_loan_installment' column based on EDA\n",
    "df_train = df_train.drop(['requested_loan_installment'],axis=1)\n",
    "df_test = df_test.drop(['requested_loan_installment'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out the unwanted rows from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NaN in 'requested_loan_amount' column\n",
    "###### Since there is no requested_loan_amount, the loan should not be approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_nan_train = df_train[df_train[['requested_loan_amount']].isna().any(axis=1)]\n",
    "\n",
    "# Want to know the customer_id that has loan_approval_status == 1\n",
    "# In order to remove these data from train dataset\n",
    "id_extracted_nan_train = extracted_nan_train[extracted_nan_train['loan_approval_status'] == 1]\n",
    "\n",
    "# Put the customer_id into a list - 148 rows\n",
    "id_removed_nan_rla_list = id_extracted_nan_train['customer_id'].unique()\n",
    "\n",
    "# Remove the customer_id from df_train\n",
    "condition = (df_train['customer_id'].isin(id_removed_nan_rla_list))\n",
    "df_train_filtered = df_train[~(condition)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dob > lead_creation_date\n",
    "###### It is impossible to have dob > lead_creation_date, and these data is only 0.0764% of the total training data. Therefore, it is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_year_train = df_train.copy()\n",
    "extracted_year_train['dob_year'] = pd.DatetimeIndex(extracted_year_train['dob']).year\n",
    "extracted_year_train['lead_year'] = pd.DatetimeIndex(extracted_year_train['lead_creation_date']).year\n",
    "\n",
    "extracted_year_train['TF'] = np.where(extracted_year_train['dob_year'] > 2016, 1, 0)\n",
    "\n",
    "# Want to know the customer_id\n",
    "# In order to remove these data from train dataset\n",
    "id_extracted_year_train = extracted_year_train[extracted_year_train['TF'] == 1]\n",
    "\n",
    "# Put the customer_id into a list\n",
    "id_removed_year_list = id_extracted_year_train['customer_id'].unique()\n",
    "\n",
    "# Remove the customer_id from df_train_filtered\n",
    "condition = (df_train_filtered['customer_id'].isin(id_removed_year_list))\n",
    "df_train_filtered = df_train_filtered[~(condition)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with outliers (numeric columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the quartiles\n",
    "q1, q3 = np.percentile(df_train_filtered['monthly_income'], [25, 75])\n",
    "# Calculate the interquartile range\n",
    "iqr = q3 - q1\n",
    "# Calculate the lower and upper bounds\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "# Drop the outliers\n",
    "clean_data = df_train_filtered[(df_train_filtered['monthly_income'] >= lower_bound) \n",
    "                               & (df_train_filtered['monthly_income'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                     0\n",
       "gender                          0\n",
       "dob                             8\n",
       "lead_creation_date              0\n",
       "city_code                       0\n",
       "area_code                     507\n",
       "employer_code                   0\n",
       "employer_category1           2487\n",
       "employer_category2           2668\n",
       "monthly_income                  0\n",
       "bank_code                       0\n",
       "bank_acc_type                6141\n",
       "marketing_source                0\n",
       "marketing_category1             0\n",
       "marketing_category2             0\n",
       "current_loan_installment       32\n",
       "requested_loan_amount       19434\n",
       "loan_repayment              19434\n",
       "interest_rate               32565\n",
       "loan_approval_status            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values\n",
    "clean_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_loan_installment</th>\n",
       "      <th>requested_loan_amount</th>\n",
       "      <th>loan_repayment</th>\n",
       "      <th>interest_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>40950.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.387415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>38531.995062</td>\n",
       "      <td>3.921012</td>\n",
       "      <td>19.347218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2063.04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>38531.995062</td>\n",
       "      <td>3.921012</td>\n",
       "      <td>19.347218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>682.50</td>\n",
       "      <td>51450.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.545335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47640</th>\n",
       "      <td>242.55</td>\n",
       "      <td>26250.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47641</th>\n",
       "      <td>0.00</td>\n",
       "      <td>47250.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47642</th>\n",
       "      <td>840.00</td>\n",
       "      <td>31907.718005</td>\n",
       "      <td>3.808444</td>\n",
       "      <td>17.755997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47643</th>\n",
       "      <td>441.00</td>\n",
       "      <td>35054.249607</td>\n",
       "      <td>3.861914</td>\n",
       "      <td>18.511827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47644</th>\n",
       "      <td>0.00</td>\n",
       "      <td>45150.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47645 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       current_loan_installment  requested_loan_amount  loan_repayment  \\\n",
       "0                          0.00           40950.000000        5.000000   \n",
       "1                          0.00           38531.995062        3.921012   \n",
       "2                       2063.04           21000.000000        5.000000   \n",
       "3                          0.00           38531.995062        3.921012   \n",
       "4                        682.50           51450.000000        5.000000   \n",
       "...                         ...                    ...             ...   \n",
       "47640                    242.55           26250.000000        4.000000   \n",
       "47641                      0.00           47250.000000        5.000000   \n",
       "47642                    840.00           31907.718005        3.808444   \n",
       "47643                    441.00           35054.249607        3.861914   \n",
       "47644                      0.00           45150.000000        5.000000   \n",
       "\n",
       "       interest_rate  \n",
       "0          19.387415  \n",
       "1          19.347218  \n",
       "2          15.190000  \n",
       "3          19.347218  \n",
       "4          16.545335  \n",
       "...              ...  \n",
       "47640      14.553000  \n",
       "47641      19.600000  \n",
       "47642      17.755997  \n",
       "47643      18.511827  \n",
       "47644      19.600000  \n",
       "\n",
       "[47645 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "clean_data_numeric = clean_data[['current_loan_installment', 'requested_loan_amount', 'loan_repayment', 'interest_rate']]\n",
    "\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit(clean_data_numeric)\n",
    "column_imputed = pd.DataFrame(imp.transform(clean_data_numeric), columns=['current_loan_installment', 'requested_loan_amount', 'loan_repayment', 'interest_rate'])\n",
    "column_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47645, 20)\n"
     ]
    }
   ],
   "source": [
    "# Drop the original numeric column that have missing values\n",
    "clean_data = clean_data.drop(['current_loan_installment', 'requested_loan_amount', 'loan_repayment', 'interest_rate'], axis=1)\n",
    "\n",
    "clean_data2 = pd.concat([clean_data.reset_index(drop=True), column_imputed.reset_index(drop=True)], axis=1)\n",
    "print(clean_data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                    0\n",
       "gender                         0\n",
       "dob                            8\n",
       "lead_creation_date             0\n",
       "city_code                      0\n",
       "area_code                    507\n",
       "employer_code                  0\n",
       "employer_category1          2487\n",
       "employer_category2          2668\n",
       "monthly_income                 0\n",
       "bank_code                      0\n",
       "bank_acc_type               6141\n",
       "marketing_source               0\n",
       "marketing_category1            0\n",
       "marketing_category2            0\n",
       "loan_approval_status           0\n",
       "current_loan_installment       0\n",
       "requested_loan_amount          0\n",
       "loan_repayment                 0\n",
       "interest_rate                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As for the missing values in categorical columns,\n",
    "can just fill the missing value with any value that are not in that particular column\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data2['area_code'] = clean_data2['area_code'].fillna(4)\n",
    "clean_data2['employer_category1'] = clean_data2['employer_category1'].fillna(4)\n",
    "clean_data2['employer_category2'] = clean_data2['employer_category2'].fillna(5)\n",
    "clean_data2['bank_acc_type'] = clean_data2['bank_acc_type'].fillna(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38116, 16)\n",
      "(9529, 16)\n"
     ]
    }
   ],
   "source": [
    "# Remove columns not required\n",
    "df_train_data = clean_data2.drop(columns = ['customer_id', 'dob', 'lead_creation_date'], axis=1)\n",
    "\n",
    "# Set the independent and dependent variables\n",
    "X = df_train_data.drop(['loan_approval_status'], axis=1)\n",
    "y = df_train_data['loan_approval_status']\n",
    "\n",
    "# train test splie 80:20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=37)\n",
    "\n",
    "# print the shape of X_train and X_test\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "oversample = RandomOverSampler(sampling_strategy=0.8)\n",
    "x_over, y_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 30178, number of negative: 37723\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 67901, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444441 -> initscore=-0.223157\n",
      "[LightGBM] [Info] Start training from score -0.223157\n",
      "[1 0 0 ... 0 0 0]\n",
      "0.9247560079756533\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Creating an object for model and fitting it on training data set \n",
    "model = LGBMClassifier()\n",
    "model.fit(x_over, y_over) # After oversampling (RandomOverSampler)\n",
    " \n",
    "# Predicting the Target variable\n",
    "pred = model.predict(X_test)\n",
    "print(pred)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use train LightGBM to predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Remove columns not required\n",
    "df_test_data = df_test.drop(columns = ['customer_id', 'dob', 'lead_creation_date'], axis=1)\n",
    "\n",
    "## predict test class\n",
    "x_pred = model.predict(df_test_data)\n",
    "print(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pandas dataframe from numpy array\n",
    "submission = pd.DataFrame({'id': np.arange(1,13941), 'class': x_pred})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
